# Large Language Models (LLMs) As Judges: Identifying Fake News Headlines
This repository serves as our code submission for our final project in DATA 25900: Ethics, Fairness, Responsibility, and Privacy in Data Science at The University of Chicago. In this repository, you can find our testing code, generated and collected data, and our statistical analysis. 

According to YouGov, 53% of Americans see what they believe to be 'fake news' every day. Given the prevalence of fake news and the emergence of LLMs as a popular tool to make sense of information, it follows that people may turn to LLMs to confirm the validity of news headlines. Additionally, and more broadly, LLM-as-a-judge techniques are being employed in the world of data science for language processing tasks. We would like to assess both the ethicality and efficacy of applying these methods when dealing with fake news headlines with real world impacts.

## Central Project Question
Should **Large Language Models** be trusted to help identify **fake news headlines**?

## Group Members
- Isaac Harlem (isaacharlem@uchicago.edu)
- Annie Reynolds (anniereynolds@uchicago.edu)

## Install Requirements

    cd <project-directory>
    conda install python==3.9
    pip install -r requirements.txt

## LLM Testing
- Please follow the instructions [here](https://github.com/isaacharlem/llm-as-judge-fake-news/blob/master/llm_test/README.md)

## Data Documentation
- For more information about the datasets, please click [here](https://github.com/isaacharlem/llm-as-judge-fake-news/blob/master/data/README.md)